{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[detect] output:\n",
      "{'result': {'boxes': [[[183, 163], [240, 163], [240, 247], [183, 247]], [[253, 163], [356, 160], [359, 247], [255, 250]], [[373, 175], [406, 172], [410, 227], [377, 229]], [[160, 358], [342, 353], [344, 414], [161, 419]], [[364, 357], [619, 353], [620, 431], [366, 435]], [[318, 459], [446, 457], [447, 521], [319, 524]], [[457, 456], [666, 448], [668, 508], [459, 515]], [[179, 612], [236, 610], [239, 694], [182, 696]], [[251, 613], [394, 613], [394, 688], [251, 688]], [[426, 626], [563, 626], [563, 685], [426, 685]], [[587, 617], [869, 617], [869, 683], [587, 683]], [[176, 799], [429, 799], [429, 884], [176, 884]], [[534, 782], [655, 782], [655, 870], [534, 870]], [[439, 801], [506, 801], [506, 859], [439, 859]], [[698, 807], [756, 807], [756, 867], [698, 867]], [[784, 801], [919, 801], [919, 882], [784, 882]]]}}\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a17104899892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-a17104899892>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkakao_ocr_recognize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;31m#     print(\"[recognize] output:\\n{}\\n\".format(json.(output, sort_keys=True, indent=2)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[recognize] output:\\n{}\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m     return loads(fp.read(),\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "LIMIT_PX = 1024\n",
    "LIMIT_BYTE = 1024*1024  # 1MB\n",
    "LIMIT_BOX = 40\n",
    "\n",
    "\n",
    "def kakao_ocr_resize(image_path: str):\n",
    "    \"\"\"\n",
    "    ocr detect/recognize api helper\n",
    "    ocr api의 제약사항이 넘어서는 이미지는 요청 이전에 전처리가 필요.\n",
    "\n",
    "    pixel 제약사항 초과: resize\n",
    "    용량 제약사항 초과  : 다른 포맷으로 압축, 이미지 분할 등의 처리 필요. (예제에서 제공하지 않음)\n",
    "\n",
    "    :param image_path: 이미지파일 경로\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    if LIMIT_PX < height or LIMIT_PX < width:\n",
    "        ratio = float(LIMIT_PX) / max(height, width)\n",
    "        image = cv2.resize(image, None, fx=ratio, fy=ratio)\n",
    "        height, width, _ = height, width, _ = image.shape\n",
    "\n",
    "        # api 사용전에 이미지가 resize된 경우, recognize시 resize된 결과를 사용해야함.\n",
    "        image_path = \"{}_resized.jpg\".format(image_path)\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        return image_path\n",
    "    return None\n",
    "\n",
    "\n",
    "def kakao_ocr_detect(image_path: str, appkey: str):\n",
    "    \"\"\"\n",
    "    detect api request example\n",
    "    :param image_path: 이미지파일 경로\n",
    "    :param appkey: 카카오 앱 REST API 키\n",
    "    \"\"\"\n",
    "    API_URL = 'https://kapi.kakao.com/v1/vision/text/detect'\n",
    "\n",
    "    headers = {'Authorization': 'KakaoAK {}'.format(appkey)}\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    jpeg_image = cv2.imencode(\".jpg\", image)[1]\n",
    "    data = jpeg_image.tobytes()\n",
    "\n",
    "    return requests.post(API_URL, headers=headers, files={\"file\": data})\n",
    "\n",
    "\n",
    "def kakao_ocr_recognize(image_path: str, boxes: list, appkey: str):\n",
    "    \"\"\"\n",
    "    recognize api request example\n",
    "    :param boxes: 감지된 영역 리스트. Canvas 좌표계: 좌상단이 (0,0) / 우상단이 (limit,0)\n",
    "                    감지된 영역중 좌상단 점을 기준으로 시계방향 순서, 좌상->우상->우하->좌하\n",
    "                    ex) [[[0,0],[1,0],[1,1],[0,1]], [[1,1],[2,1],[2,2],[1,2]], ...]\n",
    "    :param image_path: 이미지 파일 경로\n",
    "    :param appkey: 카카오 앱 REST API 키\n",
    "    \"\"\"\n",
    "    API_URL = 'https://kapi.kakao.com/v1/vision/text/recognize'\n",
    "\n",
    "    headers = {'Authorization': 'KakaoAK {}'.format(appkey)}\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    jpeg_image = cv2.imencode(\".jpg\", image)[1]\n",
    "    data = jpeg_image.tobytes()\n",
    "\n",
    "    return requests.post(API_URL, headers=headers, files={\"file\": data}, data={\"boxes\": json.dumps(boxes)})\n",
    "\n",
    "\n",
    "def main():\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Please run with args: $ python example.py /path/to/image appkey\")\n",
    "    # image_path, appkey = sys.argv[1], sys.argv[2]\n",
    "    \n",
    "    image_path = 'C:/Users/kt/Desktop/THIS.jpg'\n",
    "    appkey = 'MY_API_KEY",
    "    resize_impath = kakao_ocr_resize(image_path)\n",
    "    if resize_impath is not None:\n",
    "        image_path = resize_impath\n",
    "        print(\"원본 대신 리사이즈된 이미지를 사용합니다.\")\n",
    "\n",
    "    output = kakao_ocr_detect(image_path, appkey).json()\n",
    "    print(\"[detect] output:\\n{}\\n\".format(output))\n",
    "\n",
    "    boxes = output[\"result\"][\"boxes\"]\n",
    "    boxes = boxes[:min(len(boxes), LIMIT_BOX)]\n",
    "    output = kakao_ocr_recognize(image_path, boxes, appkey).json()\n",
    "#     print(\"[recognize] output:\\n{}\\n\".format(json.(output, sort_keys=True, indent=2)))\n",
    "    print(\"[recognize] output:\\n{}\\n\",json.load(output,encoding = 'utf-8'))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
